{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6beba100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import pyrealsense2 as rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3e7aee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/physine/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-11-3 torch 1.7.1 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3011.375MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === pytorch - yolo === #\n",
    "\n",
    "#from IPython.display import display\n",
    "#from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "\n",
    "#config_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.cfg\" # the YOLO net weights file\n",
    "#weights_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.weights\" # weights_path = \"weights/yolov3-tiny.weights\"\n",
    "#labels_path = \"/usr/local/lib/python3.8/dist-packages/yolo/data/coco.names\"\n",
    "img_path2 = \"/home/physine/Documents/FYP/images/original.jpg\" # crowded sence\n",
    "img_path1 = \"/home/physine/Documents/FYP/images/single_biker.jpg\" # single biker\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "def run_model(img):\n",
    "    object_list = []\n",
    "    results = model(img)\n",
    "    df = results.pandas().xyxy[0]\n",
    "    t0 = time.time()\n",
    "    for index, row in df.iterrows():\n",
    "        # xmin,   ymin,   xmax,   ymax,   confidence, objectName\n",
    "        # row[0], row[1], row[2], row[3], row[4],     row[6]\n",
    "        object_list.append(row)      \n",
    "    #print(f'infrance time of img: {time.time()-t0}')\n",
    "    return object_list\n",
    "    \n",
    "imgs = [\n",
    "    \"/home/physine/Documents/FYP/images/original.jpg\",\n",
    "    \"/home/physine/Documents/FYP/images/single_biker.jpg\"\n",
    "]\n",
    "\n",
    "# for img in imgs:\n",
    "#     print('===========================================================')\n",
    "#     objects = run_model(img)\n",
    "#     for obj in objects:\n",
    "#         print('-------------------------------------------------------------')\n",
    "#         print(f'xmin =\\t{obj[0]} \\nymin =\\t{obj[1]} \\nxmax =\\t{obj[2]} \\nymax =\\t{obj[3]} \\nconfidence =\\t{obj[4]} \\nobjectName =\\t{obj[6]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d1db1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrealsense2.frameset Z16 BGR8 #10>\n",
      "<pyrealsense2.frameset Z16 BGR8 #11>\n",
      "<pyrealsense2.frameset Z16 BGR8 #12>\n",
      "<pyrealsense2.frameset Z16 BGR8 #13>\n",
      "<pyrealsense2.frameset Z16 BGR8 #14>\n",
      "<pyrealsense2.frameset Z16 BGR8 #15>\n",
      "<pyrealsense2.frameset Z16 BGR8 #16>\n",
      "<pyrealsense2.frameset Z16 BGR8 #17>\n",
      "<pyrealsense2.frameset Z16 BGR8 #18>\n",
      "<pyrealsense2.frameset Z16 BGR8 #19>\n",
      "<pyrealsense2.frameset Z16 BGR8 #20>\n",
      "<pyrealsense2.frameset Z16 BGR8 #21>\n",
      "<pyrealsense2.frameset Z16 BGR8 #22>\n",
      "<pyrealsense2.frameset Z16 BGR8 #23>\n",
      "<pyrealsense2.frameset Z16 BGR8 #24>\n",
      "<pyrealsense2.frameset Z16 BGR8 #25>\n",
      "<pyrealsense2.frameset Z16 BGR8 #26>\n",
      "<pyrealsense2.frameset Z16 BGR8 #27>\n",
      "<pyrealsense2.frameset Z16 BGR8 #28>\n",
      "<pyrealsense2.frameset Z16 BGR8 #29>\n",
      "<pyrealsense2.frameset Z16 BGR8 #30>\n",
      "<pyrealsense2.frameset Z16 BGR8 #31>\n",
      "<pyrealsense2.frameset Z16 BGR8 #32>\n",
      "<pyrealsense2.frameset Z16 BGR8 #33>\n",
      "<pyrealsense2.frameset Z16 BGR8 #34>\n",
      "<pyrealsense2.frameset Z16 BGR8 #35>\n",
      "<pyrealsense2.frameset Z16 BGR8 #36>\n",
      "<pyrealsense2.frameset Z16 BGR8 #37>\n",
      "<pyrealsense2.frameset Z16 BGR8 #38>\n",
      "<pyrealsense2.frameset Z16 BGR8 #39>\n",
      "<pyrealsense2.frameset Z16 BGR8 #40>\n",
      "<pyrealsense2.frameset Z16 BGR8 #41>\n",
      "<pyrealsense2.frameset Z16 BGR8 #42>\n",
      "<pyrealsense2.frameset Z16 BGR8 #43>\n",
      "<pyrealsense2.frameset Z16 BGR8 #44>\n",
      "<pyrealsense2.frameset Z16 BGR8 #45>\n",
      "<pyrealsense2.frameset Z16 BGR8 #46>\n",
      "<pyrealsense2.frameset Z16 BGR8 #47>\n",
      "<pyrealsense2.frameset Z16 BGR8 #48>\n",
      "<pyrealsense2.frameset Z16 BGR8 #49>\n",
      "<pyrealsense2.frameset Z16 BGR8 #50>\n",
      "<pyrealsense2.frameset Z16 BGR8 #51>\n",
      "<pyrealsense2.frameset Z16 BGR8 #52>\n",
      "<pyrealsense2.frameset Z16 BGR8 #53>\n",
      "<pyrealsense2.frameset Z16 BGR8 #54>\n",
      "<pyrealsense2.frameset Z16 BGR8 #55>\n",
      "<pyrealsense2.frameset Z16 BGR8 #56>\n",
      "<pyrealsense2.frameset Z16 BGR8 #57>\n",
      "<pyrealsense2.frameset Z16 BGR8 #58>\n",
      "<pyrealsense2.frameset Z16 BGR8 #59>\n",
      "<pyrealsense2.frameset Z16 BGR8 #60>\n",
      "<pyrealsense2.frameset Z16 BGR8 #61>\n",
      "<pyrealsense2.frameset Z16 BGR8 #62>\n",
      "<pyrealsense2.frameset Z16 BGR8 #63>\n",
      "<pyrealsense2.frameset Z16 BGR8 #64>\n",
      "<pyrealsense2.frameset Z16 BGR8 #65>\n",
      "<pyrealsense2.frameset Z16 BGR8 #66>\n",
      "<pyrealsense2.frameset Z16 BGR8 #67>\n",
      "<pyrealsense2.frameset Z16 BGR8 #68>\n",
      "<pyrealsense2.frameset Z16 BGR8 #69>\n",
      "<pyrealsense2.frameset Z16 BGR8 #70>\n",
      "<pyrealsense2.frameset Z16 BGR8 #71>\n",
      "<pyrealsense2.frameset Z16 BGR8 #72>\n",
      "<pyrealsense2.frameset Z16 BGR8 #73>\n",
      "<pyrealsense2.frameset Z16 BGR8 #74>\n",
      "<pyrealsense2.frameset Z16 BGR8 #75>\n",
      "<pyrealsense2.frameset Z16 BGR8 #76>\n",
      "<pyrealsense2.frameset Z16 BGR8 #77>\n",
      "<pyrealsense2.frameset Z16 BGR8 #78>\n",
      "<pyrealsense2.frameset Z16 BGR8 #79>\n",
      "<pyrealsense2.frameset Z16 BGR8 #80>\n",
      "<pyrealsense2.frameset Z16 BGR8 #81>\n",
      "<pyrealsense2.frameset Z16 BGR8 #82>\n",
      "<pyrealsense2.frameset Z16 BGR8 #83>\n",
      "<pyrealsense2.frameset Z16 BGR8 #84>\n",
      "<pyrealsense2.frameset Z16 BGR8 #85>\n",
      "<pyrealsense2.frameset Z16 BGR8 #86>\n",
      "<pyrealsense2.frameset Z16 BGR8 #87>\n",
      "<pyrealsense2.frameset Z16 BGR8 #88>\n",
      "<pyrealsense2.frameset Z16 BGR8 #89>\n",
      "<pyrealsense2.frameset Z16 BGR8 #90>\n",
      "<pyrealsense2.frameset Z16 BGR8 #91>\n",
      "<pyrealsense2.frameset Z16 BGR8 #92>\n",
      "<pyrealsense2.frameset Z16 BGR8 #92>\n",
      "<pyrealsense2.frameset Z16 BGR8 #93>\n",
      "<pyrealsense2.frameset Z16 BGR8 #94>\n",
      "<pyrealsense2.frameset Z16 BGR8 #95>\n",
      "<pyrealsense2.frameset Z16 BGR8 #96>\n",
      "<pyrealsense2.frameset Z16 BGR8 #97>\n",
      "<pyrealsense2.frameset Z16 BGR8 #98>\n",
      "<pyrealsense2.frameset Z16 BGR8 #99>\n",
      "<pyrealsense2.frameset Z16 BGR8 #100>\n",
      "<pyrealsense2.frameset Z16 BGR8 #101>\n",
      "<pyrealsense2.frameset Z16 BGR8 #102>\n",
      "<pyrealsense2.frameset Z16 BGR8 #103>\n",
      "<pyrealsense2.frameset Z16 BGR8 #104>\n",
      "<pyrealsense2.frameset Z16 BGR8 #105>\n",
      "<pyrealsense2.frameset Z16 BGR8 #106>\n",
      "<pyrealsense2.frameset Z16 BGR8 #107>\n",
      "<pyrealsense2.frameset Z16 BGR8 #108>\n",
      "<pyrealsense2.frameset Z16 BGR8 #109>\n",
      "<pyrealsense2.frameset Z16 BGR8 #110>\n",
      "<pyrealsense2.frameset Z16 BGR8 #111>\n",
      "<pyrealsense2.frameset Z16 BGR8 #112>\n",
      "<pyrealsense2.frameset Z16 BGR8 #113>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-e57e491d4aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdepth_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_depth_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcolor_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# === pyrealsense2 === #\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "color_path = 'V00P00A00C00_rgb.avi'\n",
    "depth_path = 'V00P00A00C00_depth.avi'\n",
    "colorwriter = cv2.VideoWriter(color_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "depthwriter = cv2.VideoWriter(depth_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "\n",
    "pipeline.start(config)\n",
    "\n",
    "frames = pipeline.wait_for_frames()\n",
    "print(frames)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     while True:     \n",
    "        \n",
    "#         frames = pipeline.wait_for_frames()        \n",
    "#         depth_frame = frames.get_depth_frame()\n",
    "#         color_frame = frames.get_color_frame()\n",
    "#         if not depth_frame or not color_frame:\n",
    "#             continue\n",
    "        \n",
    "#         #convert images to numpy arrays\n",
    "#         depth_image = np.asanyarray(depth_frame.get_data())\n",
    "#         color_image = np.asanyarray(color_frame.get_data())\n",
    "#         depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        \n",
    "#         colorwriter.write(color_image)\n",
    "#         depthwriter.write(depth_colormap)\n",
    "        \n",
    "#         cv2.imshow('Stream', color_image)\n",
    "#         #cv2.imshow('Stream', depth_colormap)\n",
    "        \n",
    "#         if cv2.waitKey(1) == ord(\"q\"):\n",
    "#             break\n",
    "# finally:\n",
    "#     colorwriter.release()\n",
    "#     depthwriter.release()\n",
    "#     pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === open3d === #\n",
    "\n",
    "import os\n",
    "import open3d.ml as _ml3d\n",
    "#import open3d.ml.torch as ml3d\n",
    "\n",
    "cfg_file = \"ml3d/configs/pointpillars_kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.PointPillars(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = \"/path/to/your/dataset\"\n",
    "dataset = ml3d.datasets.KITTI(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "... \n",
    "# run inference on a single example.\n",
    "result = pipeline.run_inference(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1decfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/physine/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-11-3 torch 1.7.1 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3011.375MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "infrance time of img: 0.0009565353393554688\n",
      "-------------------------------------------------------------\n",
      "xmin =\t565.9375 \n",
      "ymin =\t425.9375 \n",
      "xmax =\t678.75 \n",
      "ymax =\t691.875 \n",
      "confidence =\t0.86376953125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1066.875 \n",
      "ymin =\t436.875 \n",
      "xmax =\t1235.625 \n",
      "ymax =\t758.125 \n",
      "confidence =\t0.85888671875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t945.625 \n",
      "ymin =\t393.4375 \n",
      "xmax =\t1013.125 \n",
      "ymax =\t574.6875 \n",
      "confidence =\t0.85888671875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t21.0546875 \n",
      "ymin =\t621.875 \n",
      "xmax =\t174.0625 \n",
      "ymax =\t865.625 \n",
      "confidence =\t0.82666015625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t144.375 \n",
      "ymin =\t443.125 \n",
      "xmax =\t205.625 \n",
      "ymax =\t660.625 \n",
      "confidence =\t0.8154296875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t212.8125 \n",
      "ymin =\t440.3125 \n",
      "xmax =\t328.4375 \n",
      "ymax =\t696.25 \n",
      "confidence =\t0.81201171875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t12.65625 \n",
      "ymin =\t465.0 \n",
      "xmax =\t173.75 \n",
      "ymax =\t788.75 \n",
      "confidence =\t0.8115234375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1435.0 \n",
      "ymin =\t470.0 \n",
      "xmax =\t1577.5 \n",
      "ymax =\t872.5 \n",
      "confidence =\t0.7958984375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t573.75 \n",
      "ymin =\t544.0625 \n",
      "xmax =\t665.625 \n",
      "ymax =\t720.0 \n",
      "confidence =\t0.7939453125 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1382.5 \n",
      "ymin =\t400.625 \n",
      "xmax =\t1490.0 \n",
      "ymax =\t748.75 \n",
      "confidence =\t0.7578125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t236.875 \n",
      "ymin =\t551.25 \n",
      "xmax =\t315.9375 \n",
      "ymax =\t723.75 \n",
      "confidence =\t0.74658203125 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t862.5 \n",
      "ymin =\t444.6875 \n",
      "xmax =\t951.25 \n",
      "ymax =\t703.125 \n",
      "confidence =\t0.7431640625 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1237.5 \n",
      "ymin =\t387.5 \n",
      "xmax =\t1297.5 \n",
      "ymax =\t563.75 \n",
      "confidence =\t0.71484375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t861.25 \n",
      "ymin =\t583.75 \n",
      "xmax =\t952.5 \n",
      "ymax =\t770.0 \n",
      "confidence =\t0.69287109375 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1081.25 \n",
      "ymin =\t353.4375 \n",
      "xmax =\t1122.5 \n",
      "ymax =\t480.3125 \n",
      "confidence =\t0.68408203125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t715.0 \n",
      "ymin =\t404.6875 \n",
      "xmax =\t780.0 \n",
      "ymax =\t580.3125 \n",
      "confidence =\t0.68310546875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t542.1875 \n",
      "ymin =\t309.0625 \n",
      "xmax =\t575.3125 \n",
      "ymax =\t412.1875 \n",
      "confidence =\t0.56982421875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1538.75 \n",
      "ymin =\t452.5 \n",
      "xmax =\t1586.25 \n",
      "ymax =\t572.5 \n",
      "confidence =\t0.51611328125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t922.5 \n",
      "ymin =\t335.625 \n",
      "xmax =\t960.0 \n",
      "ymax =\t430.0 \n",
      "confidence =\t0.50634765625 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1053.75 \n",
      "ymin =\t40.0 \n",
      "xmax =\t1085.0 \n",
      "ymax =\t101.875 \n",
      "confidence =\t0.447021484375 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1523.75 \n",
      "ymin =\t334.0625 \n",
      "xmax =\t1566.25 \n",
      "ymax =\t455.9375 \n",
      "confidence =\t0.411865234375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t999.375 \n",
      "ymin =\t340.625 \n",
      "xmax =\t1024.375 \n",
      "ymax =\t423.75 \n",
      "confidence =\t0.40771484375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1393.75 \n",
      "ymin =\t121.40625 \n",
      "xmax =\t1421.25 \n",
      "ymax =\t166.09375 \n",
      "confidence =\t0.404052734375 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1368.75 \n",
      "ymin =\t400.625 \n",
      "xmax =\t1431.25 \n",
      "ymax =\t550.625 \n",
      "confidence =\t0.36083984375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t676.25 \n",
      "ymin =\t446.25 \n",
      "xmax =\t722.5 \n",
      "ymax =\t518.125 \n",
      "confidence =\t0.308837890625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1327.5 \n",
      "ymin =\t332.8125 \n",
      "xmax =\t1362.5 \n",
      "ymax =\t439.0625 \n",
      "confidence =\t0.30126953125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1251.875 \n",
      "ymin =\t149.84375 \n",
      "xmax =\t1281.25 \n",
      "ymax =\t234.84375 \n",
      "confidence =\t0.275634765625 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1402.5 \n",
      "ymin =\t120.0 \n",
      "xmax =\t1440.0 \n",
      "ymax =\t166.875 \n",
      "confidence =\t0.271728515625 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1206.25 \n",
      "ymin =\t309.375 \n",
      "xmax =\t1295.0 \n",
      "ymax =\t380.625 \n",
      "confidence =\t0.259765625 \n",
      "objectName =\tcar\n",
      "===========================================================\n",
      "infrance time of img: 0.00018978118896484375\n",
      "-------------------------------------------------------------\n",
      "xmin =\t146.484375 \n",
      "ymin =\t266.8984375 \n",
      "xmax =\t658.203125 \n",
      "ymax =\t614.75 \n",
      "confidence =\t0.8369140625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t195.3125 \n",
      "ymin =\t58.304683685302734 \n",
      "xmax =\t534.765625 \n",
      "ymax =\t505.375 \n",
      "confidence =\t0.8125 \n",
      "objectName =\tperson\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "       xmin        ymin        xmax     ymax  confidence  class     name\n",
    "0  146.484375  266.898438  658.203125  614.750    0.836914      1  bicycle\n",
    "1  195.312500   58.304684  534.765625  505.375    0.812500      0   person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fb821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
