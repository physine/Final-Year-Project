{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6beba100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import pyrealsense2 as rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1db1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === pyrealsense2 === #\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "color_path = 'V00P00A00C00_rgb.avi'\n",
    "depth_path = 'V00P00A00C00_depth.avi'\n",
    "colorwriter = cv2.VideoWriter(color_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "depthwriter = cv2.VideoWriter(depth_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "\n",
    "pipeline.start(config)\n",
    "try:\n",
    "    while True:     \n",
    "        \n",
    "        frames = pipeline.wait_for_frames()        \n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        #convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        \n",
    "        colorwriter.write(color_image)\n",
    "        depthwriter.write(depth_colormap)\n",
    "        \n",
    "        cv2.imshow('Stream', color_image)\n",
    "        #cv2.imshow('Stream', depth_colormap)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "finally:\n",
    "    colorwriter.release()\n",
    "    depthwriter.release()\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === open3d === #\n",
    "\n",
    "import os\n",
    "import open3d.ml as _ml3d\n",
    "#import open3d.ml.torch as ml3d\n",
    "\n",
    "cfg_file = \"ml3d/configs/pointpillars_kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.PointPillars(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = \"/path/to/your/dataset\"\n",
    "dataset = ml3d.datasets.KITTI(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "... \n",
    "# run inference on a single example.\n",
    "result = pipeline.run_inference(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1decfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img 1\n",
      "()\n",
      "img 2\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import yolo\n",
    "\n",
    "config_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.cfg\" # the YOLO net weights file\n",
    "weights_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.weights\" # weights_path = \"weights/yolov3-tiny.weights\"\n",
    "labels_path = \"/usr/local/lib/python3.8/dist-packages/yolo/data/coco.names\"\n",
    "img_path2 = \"/home/physine/Documents/FYP/images/original.jpg\" # crowded sence\n",
    "img_path = \"/home/physine/Documents/FYP/images/single_biker.jpg\" # single biker\n",
    "\n",
    "WHITE = (255, 255, 255)\n",
    "#img = None\n",
    "#img0 = None\n",
    "#outputs = None\n",
    "\n",
    "# Load names of classes and get random colors\n",
    "classes = open(labels_path).read().strip().split('\\n')\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network.\n",
    "net = cv.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "# net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "# determine the output layer\n",
    "ln = net.getLayerNames()\n",
    "#ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "ln = [ln[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    #global img, img0, outputs, ln\n",
    "\n",
    "    img0 = cv.imread(path)\n",
    "    img = img0.copy()\n",
    "    \n",
    "    blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    #t0 = time.time()\n",
    "    output = net.forward(ln)\n",
    "    #t = time.time() - t0\n",
    "\n",
    "    # combine the 3 output groups into 1 (10647, 85)\n",
    "    # large objects (507, 85)\n",
    "    # medium objects (2028, 85)\n",
    "    # small objects (8112, 85)\n",
    "    ##output = np.vstack(output) # (10647, 85)\n",
    "    return output\n",
    "    #post_process(img, outputs, 0.5)\n",
    "    #cv.imshow('window',  img)\n",
    "    #cv.displayOverlay('window', f'forward propagation time={t:.3}')\n",
    "    #cv.waitKey(0)\n",
    "\n",
    "def post_process(img, outputs, conf):\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    for output in outputs:\n",
    "        scores = output[5:]\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        if confidence > conf:\n",
    "            x, y, w, h = output[:4] * np.array([W, H, W, H])\n",
    "            p0 = int(x - w//2), int(y - h//2)\n",
    "            p1 = int(x + w//2), int(y + h//2)\n",
    "            boxes.append([*p0, int(w), int(h)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)\n",
    "            #cv.rectangle(img, p0, p1, WHITE, 1)\n",
    "\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, conf, conf-0.1)\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            color = [int(c) for c in colors[classIDs[i]]]\n",
    "            cv.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}: {:.4f}\".format(classes[classIDs[i]], confidences[i])\n",
    "            cv.putText(img, text, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "def trackbar(x):\n",
    "    global img, img0\n",
    "    conf = x/100\n",
    "    img0 = cv.imread(img_path)\n",
    "    img = img0.copy()\n",
    "            \n",
    "    post_process(img, outputs, conf)\n",
    "    cv.displayOverlay('window', f'confidence level={conf}')\n",
    "    cv.imshow('window', img)\n",
    "\n",
    "cv.namedWindow('window')\n",
    "#cv.createTrackbar('confidence', 'window', 50, 100, trackbar)\n",
    "\n",
    "print(\"img 1\")\n",
    "output = load_image(img_path)\n",
    "#print(output.shape)\n",
    "scores = output[5:]\n",
    "print(scores)\n",
    "\n",
    "print(\"img 2\")\n",
    "output = load_image(img_path2)\n",
    "#print(output)\n",
    "\n",
    "# load_image('images/zoo.jpg')\n",
    "# load_image('images/kitchen.jpg')\n",
    "# load_image('images/airport.jpg')\n",
    "# load_image('images/tennis.jpg')\n",
    "# load_image('images/wine.jpg')\n",
    "# load_image('images/bicycle.jpg')\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "# # test img\n",
    "# display(Image.open(img_path))\n",
    "\n",
    "# # load the net\n",
    "# net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# # print the 254 components\n",
    "# ln = net.getLayerNames()\n",
    "# #print(len(ln), ln)\n",
    "\n",
    "# # create a blob\n",
    "# img = cv2.imread(img_path)\n",
    "# resized = cv2.resize(img, dsize=(416, 416))\n",
    "# blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "# r = blob[0, 0, :, :]\n",
    "# # It has the following parameters:\n",
    "# # - the image to transform\n",
    "# # - the scale factor (1/255 to scale the pixel values to [0..1])\n",
    "# # - the size, here a 416x416 square image\n",
    "# # - the mean value (default=0)\n",
    "# # - the option swapBR=True (since OpenCV uses BGR)\n",
    "\n",
    "# cv2.imshow('blob', r)\n",
    "# text = f'Blob shape={blob.shape}'\n",
    "# cv2.displayOverlay('blob', text)\n",
    "# cv2.waitKey(1)\n",
    "\n",
    "# net.setInput(blob)\n",
    "# t0 = time.time()\n",
    "# outputs = net.forward(ln)\n",
    "# t = time.time()\n",
    "\n",
    "# cv2.displayOverlay('window', f'forward propagation time={t-t0}')\n",
    "# cv2.imshow('window',  img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# net.setInput(blob)\n",
    "# outputs = net.forward(ln)\n",
    "\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed0356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fb821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
