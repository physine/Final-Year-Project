{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6beba100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import pyrealsense2 as rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "913f0969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/physine/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-11-3 torch 1.7.1 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3011.375MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === pytorch - yolo === #\n",
    "\n",
    "#from IPython.display import display\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "\n",
    "#config_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.cfg\" # the YOLO net weights file\n",
    "#weights_path = \"/usr/local/lib/python3.8/dist-packages/yolo/yolov3.weights\" # weights_path = \"weights/yolov3-tiny.weights\"\n",
    "#labels_path = \"/usr/local/lib/python3.8/dist-packages/yolo/data/coco.names\"\n",
    "img_path2 = \"/home/physine/Documents/FYP/images/original.jpg\" # crowded sence\n",
    "img_path1 = \"/home/physine/Documents/FYP/images/single_biker.jpg\" # single biker\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "def run_model(img):\n",
    "    object_list = []\n",
    "    results = model(img)\n",
    "    df = results.pandas().xyxy[0]\n",
    "    t0 = time.time()\n",
    "    for index, row in df.iterrows():\n",
    "        # xmin,   ymin,   xmax,   ymax,   confidence, objectName\n",
    "        # row[0], row[1], row[2], row[3], row[4],     row[6]\n",
    "        object_list.append(row)      \n",
    "    print(f'infrance time of img: {time.time()-t0}')\n",
    "    return object_list\n",
    "    \n",
    "    \n",
    "def array_to_img(array):\n",
    "    return Image.fromarray(array)\n",
    "    \n",
    "imgs = [\n",
    "    \"/home/physine/Documents/FYP/images/original.jpg\",\n",
    "    \"/home/physine/Documents/FYP/images/single_biker.jpg\"\n",
    "]\n",
    "\n",
    "# for img in imgs:\n",
    "#     print('===========================================================')\n",
    "#     objects = run_model(img)\n",
    "#     for obj in objects:\n",
    "#         print('-------------------------------------------------------------')\n",
    "#         print(f'xmin =\\t{obj[0]} \\nymin =\\t{obj[1]} \\nxmax =\\t{obj[2]} \\nymax =\\t{obj[3]} \\nconfidence =\\t{obj[4]} \\nobjectName =\\t{obj[6]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d1db1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyrealsense2.pyrealsense2.BufData'>\n",
      "<class 'numpy.ndarray'>\n",
      "infrance time of img: 1.6689300537109375e-05\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === pyrealsense2 === #\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "color_path = 'V00P00A00C00_rgb.avi'\n",
    "depth_path = 'V00P00A00C00_depth.avi'\n",
    "colorwriter = cv2.VideoWriter(color_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "depthwriter = cv2.VideoWriter(depth_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    for _ in range(1):\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "             continue\n",
    "        \n",
    "        print(type(color_frame.get_data()))\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        #print(frames)\n",
    "        #print(depth_frame)\n",
    "        #print(color_frame.frame())\n",
    "\n",
    "        print(type(color_image))\n",
    "        \n",
    "        objects = run_model(Image.fromarray(color_image))\n",
    "        print(objects)\n",
    "        for obj in objects:\n",
    "            print('-------------------------------------------------------------')\n",
    "            print(f'xmin =\\t{obj[0]} \\nymin =\\t{obj[1]} \\nxmax =\\t{obj[2]} \\nymax =\\t{obj[3]} \\nconfidence =\\t{obj[4]} \\nobjectName =\\t{obj[6]}')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('error1')\n",
    "    \n",
    "pipeline.stop()\n",
    "\n",
    "# try:\n",
    "#     while True:     \n",
    "        \n",
    "#         frames = pipeline.wait_for_frames()        \n",
    "#         depth_frame = frames.get_depth_frame()\n",
    "#         color_frame = frames.get_color_frame()\n",
    "#         if not depth_frame or not color_frame:\n",
    "#             continue\n",
    "        \n",
    "#         #convert images to numpy arrays\n",
    "#         depth_image = np.asanyarray(depth_frame.get_data())\n",
    "#         color_image = np.asanyarray(color_frame.get_data())\n",
    "#         depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        \n",
    "#         colorwriter.write(color_image)\n",
    "#         depthwriter.write(depth_colormap)\n",
    "        \n",
    "#         cv2.imshow('Stream', color_image)\n",
    "#         #cv2.imshow('Stream', depth_colormap)\n",
    "        \n",
    "#         if cv2.waitKey(1) == ord(\"q\"):\n",
    "#             break\n",
    "# finally:\n",
    "#     colorwriter.release()\n",
    "#     depthwriter.release()\n",
    "#     pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "feccda7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ml3d/configs/pointpillars_kitti.yml not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-6d6f935e50e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcfg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ml3d/configs/pointpillars_kitti.yml\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ml3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPointPillars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/open3d/_ml3d/utils/config.py\u001b[0m in \u001b[0;36mload_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'File {filename} not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ml3d/configs/pointpillars_kitti.yml not found"
     ]
    }
   ],
   "source": [
    "\n",
    "# === open3d === #\n",
    "\n",
    "import os\n",
    "import open3d.ml as _ml3d\n",
    "#import open3d.ml.torch as ml3d\n",
    "\n",
    "cfg_file = \"ml3d/configs/pointpillars_kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.PointPillars(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = \"/path/to/your/dataset\"\n",
    "dataset = ml3d.datasets.KITTI(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "... \n",
    "# run inference on a single example.\n",
    "result = pipeline.run_inference(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1decfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/physine/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-11-3 torch 1.7.1 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3011.375MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "infrance time of img: 0.0009565353393554688\n",
      "-------------------------------------------------------------\n",
      "xmin =\t565.9375 \n",
      "ymin =\t425.9375 \n",
      "xmax =\t678.75 \n",
      "ymax =\t691.875 \n",
      "confidence =\t0.86376953125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1066.875 \n",
      "ymin =\t436.875 \n",
      "xmax =\t1235.625 \n",
      "ymax =\t758.125 \n",
      "confidence =\t0.85888671875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t945.625 \n",
      "ymin =\t393.4375 \n",
      "xmax =\t1013.125 \n",
      "ymax =\t574.6875 \n",
      "confidence =\t0.85888671875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t21.0546875 \n",
      "ymin =\t621.875 \n",
      "xmax =\t174.0625 \n",
      "ymax =\t865.625 \n",
      "confidence =\t0.82666015625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t144.375 \n",
      "ymin =\t443.125 \n",
      "xmax =\t205.625 \n",
      "ymax =\t660.625 \n",
      "confidence =\t0.8154296875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t212.8125 \n",
      "ymin =\t440.3125 \n",
      "xmax =\t328.4375 \n",
      "ymax =\t696.25 \n",
      "confidence =\t0.81201171875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t12.65625 \n",
      "ymin =\t465.0 \n",
      "xmax =\t173.75 \n",
      "ymax =\t788.75 \n",
      "confidence =\t0.8115234375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1435.0 \n",
      "ymin =\t470.0 \n",
      "xmax =\t1577.5 \n",
      "ymax =\t872.5 \n",
      "confidence =\t0.7958984375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t573.75 \n",
      "ymin =\t544.0625 \n",
      "xmax =\t665.625 \n",
      "ymax =\t720.0 \n",
      "confidence =\t0.7939453125 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1382.5 \n",
      "ymin =\t400.625 \n",
      "xmax =\t1490.0 \n",
      "ymax =\t748.75 \n",
      "confidence =\t0.7578125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t236.875 \n",
      "ymin =\t551.25 \n",
      "xmax =\t315.9375 \n",
      "ymax =\t723.75 \n",
      "confidence =\t0.74658203125 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t862.5 \n",
      "ymin =\t444.6875 \n",
      "xmax =\t951.25 \n",
      "ymax =\t703.125 \n",
      "confidence =\t0.7431640625 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1237.5 \n",
      "ymin =\t387.5 \n",
      "xmax =\t1297.5 \n",
      "ymax =\t563.75 \n",
      "confidence =\t0.71484375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t861.25 \n",
      "ymin =\t583.75 \n",
      "xmax =\t952.5 \n",
      "ymax =\t770.0 \n",
      "confidence =\t0.69287109375 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1081.25 \n",
      "ymin =\t353.4375 \n",
      "xmax =\t1122.5 \n",
      "ymax =\t480.3125 \n",
      "confidence =\t0.68408203125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t715.0 \n",
      "ymin =\t404.6875 \n",
      "xmax =\t780.0 \n",
      "ymax =\t580.3125 \n",
      "confidence =\t0.68310546875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t542.1875 \n",
      "ymin =\t309.0625 \n",
      "xmax =\t575.3125 \n",
      "ymax =\t412.1875 \n",
      "confidence =\t0.56982421875 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1538.75 \n",
      "ymin =\t452.5 \n",
      "xmax =\t1586.25 \n",
      "ymax =\t572.5 \n",
      "confidence =\t0.51611328125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t922.5 \n",
      "ymin =\t335.625 \n",
      "xmax =\t960.0 \n",
      "ymax =\t430.0 \n",
      "confidence =\t0.50634765625 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1053.75 \n",
      "ymin =\t40.0 \n",
      "xmax =\t1085.0 \n",
      "ymax =\t101.875 \n",
      "confidence =\t0.447021484375 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1523.75 \n",
      "ymin =\t334.0625 \n",
      "xmax =\t1566.25 \n",
      "ymax =\t455.9375 \n",
      "confidence =\t0.411865234375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t999.375 \n",
      "ymin =\t340.625 \n",
      "xmax =\t1024.375 \n",
      "ymax =\t423.75 \n",
      "confidence =\t0.40771484375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1393.75 \n",
      "ymin =\t121.40625 \n",
      "xmax =\t1421.25 \n",
      "ymax =\t166.09375 \n",
      "confidence =\t0.404052734375 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1368.75 \n",
      "ymin =\t400.625 \n",
      "xmax =\t1431.25 \n",
      "ymax =\t550.625 \n",
      "confidence =\t0.36083984375 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t676.25 \n",
      "ymin =\t446.25 \n",
      "xmax =\t722.5 \n",
      "ymax =\t518.125 \n",
      "confidence =\t0.308837890625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1327.5 \n",
      "ymin =\t332.8125 \n",
      "xmax =\t1362.5 \n",
      "ymax =\t439.0625 \n",
      "confidence =\t0.30126953125 \n",
      "objectName =\tperson\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1251.875 \n",
      "ymin =\t149.84375 \n",
      "xmax =\t1281.25 \n",
      "ymax =\t234.84375 \n",
      "confidence =\t0.275634765625 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1402.5 \n",
      "ymin =\t120.0 \n",
      "xmax =\t1440.0 \n",
      "ymax =\t166.875 \n",
      "confidence =\t0.271728515625 \n",
      "objectName =\ttraffic light\n",
      "-------------------------------------------------------------\n",
      "xmin =\t1206.25 \n",
      "ymin =\t309.375 \n",
      "xmax =\t1295.0 \n",
      "ymax =\t380.625 \n",
      "confidence =\t0.259765625 \n",
      "objectName =\tcar\n",
      "===========================================================\n",
      "infrance time of img: 0.00018978118896484375\n",
      "-------------------------------------------------------------\n",
      "xmin =\t146.484375 \n",
      "ymin =\t266.8984375 \n",
      "xmax =\t658.203125 \n",
      "ymax =\t614.75 \n",
      "confidence =\t0.8369140625 \n",
      "objectName =\tbicycle\n",
      "-------------------------------------------------------------\n",
      "xmin =\t195.3125 \n",
      "ymin =\t58.304683685302734 \n",
      "xmax =\t534.765625 \n",
      "ymax =\t505.375 \n",
      "confidence =\t0.8125 \n",
      "objectName =\tperson\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "       xmin        ymin        xmax     ymax  confidence  class     name\n",
    "0  146.484375  266.898438  658.203125  614.750    0.836914      1  bicycle\n",
    "1  195.312500   58.304684  534.765625  505.375    0.812500      0   person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fb821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
